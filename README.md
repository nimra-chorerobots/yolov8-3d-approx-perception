Cameraâ€“LiDAR perception demo using KITTI dataset.
Includes YOLOv8 2D detection, monocular depth approximation (MiDaS),
and KITTI ground-truth 3D bounding boxes visualized in both image
and LiDAR space for autonomous robotics research.

ğŸ“ Structure
kitti-yolov8-3d-approx-perception/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ kitti_3d_bbox_demo.py
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ demo_1.png
â”‚   â”œâ”€â”€ demo_2.png
â”‚   â”œâ”€â”€ demo_3.png
â”‚
â””â”€â”€ .gitignore

 
# KITTI Perception Demo: YOLOv8 + Depth + 3D Bounding Boxes

This repository demonstrates a **robotics-grade perception pipeline**
using the **KITTI dataset**, combining:

- ğŸ” **YOLOv8** for 2D object detection
- ğŸŒŠ **MiDaS** for monocular depth estimation (3D approximation)
- ğŸ“¦ **KITTI ground-truth 3D bounding boxes**
- â˜ï¸ **LiDAR point cloud visualization** (Open3D)

The goal is to visually and technically demonstrate how **real robots
perceive static and dynamic objects in 3D**.

---

## ğŸš€ Features

âœ… 2D Object Detection (YOLOv8)  
âœ… Depth Estimation per Object (MiDaS â€“ monocular)  
âœ… KITTI Ground-Truth 3D Bounding Boxes (Camera & LiDAR frames)  
âœ… Static vs Dynamic Object Classification  
âœ… Side-by-side Image + LiDAR Visualization  
âœ… Frame-by-frame playback with pause & step controls  

---

## ğŸ§  Pipeline Overview



Camera Image â”€â”€â–¶ YOLOv8 â”€â”€â–¶ 2D Boxes
â”‚
â”œâ”€â”€â–¶ MiDaS â”€â”€â–¶ Relative Depth
â”‚
LiDAR Point Cloud â”€â”€â–¶ KITTI GT â”€â”€â–¶ True 3D Boxes


This allows:
- **Fast demos on CPU**
- **Validation against true 3D geometry**
- **Scalability to PointPillars / BEV / GPU models**
---

## ğŸ“¸ Demo Results

### Camera + 3D Boxes
<img width="1257" height="463" alt="Screenshot From 2026-02-03 19-05-42" src="https://github.com/user-attachments/assets/3eb93325-3e96-4057-bd95-64a1ab660da7" />



### Multi-object Detection
<img width="1257" height="463" alt="Screenshot From 2026-02-03 19-06-04" src="https://github.com/user-attachments/assets/f0821963-8272-4e48-9824-7731a027e3b0" />


### Urban Scenario
<img width="1257" height="463" alt="Screenshot From 2026-02-03 19-06-10" src="https://github.com/user-attachments/assets/507cb8bc-35c7-43c8-83c3-9307f55e1b4a" />
<img width="1257" height="463" alt="Screenshot From 2026-02-03 19-06-20" src="https://github.com/user-attachments/assets/294cca85-720c-49b8-a6d2-475ec23258cc" />


---

## ğŸ›  Installation

### 1ï¸âƒ£ Create Conda Environment
```bash
conda create -n perception python=3.11 -y
conda activate perception

2ï¸âƒ£ Install Dependencies
pip install torch torchvision torchaudio
pip install ultralytics opencv-python matplotlib open3d timm


ğŸ“‚ Dataset Setup

Download KITTI:

data_object_image_2

data_object_velodyne

data_object_calib

data_object_label_2

Folder structure:

kitti/
â”œâ”€â”€ data_object_image_2/training/image_2
â”œâ”€â”€ data_object_velodyne/training/velodyne
â”œâ”€â”€ data_object_calib/training/calib
â”œâ”€â”€ data_object_label_2/training/label_2


Update path in code:

KITTI_ROOT = "/path/to/kitti"
